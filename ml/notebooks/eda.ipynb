{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e7ee9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Subscription Management System - Exploratory Data Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides a comprehensive exploratory data analysis of the subscription dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from preprocessing import preprocess_subscription_data\\n\",\n",
    "    \"from visualize import SubscriptionVisualizer, create_comprehensive_report\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set display options\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"pd.set_option('display.width', None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 8)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Loading and Initial Exploration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the dataset\\n\",\n",
    "    \"file_path = \\\"../data/SubscriptionCaseStudy_Dataset.xlsx\\\"\\n\",\n",
    "    \"df, preprocessor = preprocess_subscription_data(file_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumns: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nData types:\\\\n{df.dtypes}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display first few rows\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Basic statistics\\n\",\n",
    "    \"df.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Quality Assessment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for missing values\\n\",\n",
    "    \"missing_data = df.isnull().sum().sort_values(ascending=False)\\n\",\n",
    "    \"missing_percentage = (missing_data / len(df)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Missing Count': missing_data,\\n\",\n",
    "    \"    'Percentage': missing_percentage\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Missing Data Summary:\\\")\\n\",\n",
    "    \"print(missing_df[missing_df['Missing Count'] > 0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for duplicates\\n\",\n",
    "    \"duplicates = df.duplicated().sum()\\n\",\n",
    "    \"print(f\\\"Number of duplicate rows: {duplicates}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Unique values in categorical columns\\n\",\n",
    "    \"categorical_cols = df.select_dtypes(include=['object']).columns\\n\",\n",
    "    \"print(\\\"\\\\nUnique values in categorical columns:\\\")\\n\",\n",
    "    \"for col in categorical_cols:\\n\",\n",
    "    \"    print(f\\\"{col}: {df[col].nunique()} unique values\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Comprehensive Visualization Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comprehensive visualization report\\n\",\n",
    "    \"visualizer = SubscriptionVisualizer()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data overview\\n\",\n",
    "    \"visualizer.plot_data_overview(df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Churn Analysis (if churn column exists)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for churn-related columns\\n\",\n",
    "    \"churn_columns = [col for col in df.columns if 'churn' in col.lower()]\\n\",\n",
    "    \"print(f\\\"Potential churn columns: {churn_columns}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if churn_columns:\\n\",\n",
    "    \"    churn_col = churn_columns[0]\\n\",\n",
    "    \"    print(f\\\"\\\\nUsing '{churn_col}' as churn column\\\")\\n\",\n",
    "    \"    print(f\\\"Churn distribution:\\\\n{df[churn_col].value_counts()}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create churn analysis\\n\",\n",
    "    \"    visualizer.plot_churn_analysis(df, churn_col)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No churn column found in the dataset\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze numeric features\\n\",\n",
    "    \"numeric_cols = df.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"print(f\\\"Numeric columns: {numeric_cols.tolist()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(numeric_cols) > 0:\\n\",\n",
    "    \"    # Distribution plots\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n\",\n",
    "    \"    axes = axes.ravel()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, col in enumerate(numeric_cols[:4]):\\n\",\n",
    "    \"        df[col].hist(bins=30, ax=axes[i], alpha=0.7)\\n\",\n",
    "    \"        axes[i].set_title(f'Distribution of {col}')\\n\",\n",
    "    \"        axes[i].set_xlabel(col)\\n\",\n",
    "    \"        axes[i].set_ylabel('Frequency')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Correlation analysis\\n\",\n",
    "    \"if len(numeric_cols) > 1:\\n\",\n",
    "    \"    plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"    correlation_matrix = df[numeric_cols].corr()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\\n\",\n",
    "    \"    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\\n\",\n",
    "    \"                square=True, linewidths=0.5, cbar_kws={\\\"shrink\\\": .8})\\n\",\n",
    "    \"    plt.title('Correlation Matrix of Numeric Features')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Find highly correlated features\\n\",\n",
    "    \"    high_corr_pairs = []\\n\",\n",
    "    \"    for i in range(len(correlation_matrix.columns)):\\n\",\n",
    "    \"        for j in range(i+1, len(correlation_matrix.columns)):\\n\",\n",
    "    \"            if abs(correlation_matrix.iloc[i, j]) > 0.7:\\n\",\n",
    "    \"                high_corr_pairs.append((\\n\",\n",
    "    \"                    correlation_matrix.columns[i],\\n\",\n",
    "    \"                    correlation_matrix.columns[j],\\n\",\n",
    "    \"                    correlation_matrix.iloc[i, j]\\n\",\n",
    "    \"                ))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if high_corr_pairs:\\n\",\n",
    "    \"        print(\\\"\\\\nHighly correlated feature pairs (|correlation| > 0.7):\\\")\\n\",\n",
    "    \"        for pair in high_corr_pairs:\\n\",\n",
    "    \"            print(f\\\"{pair[0]} - {pair[1]}: {pair[2]:.3f}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"\\\\nNo highly correlated feature pairs found.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Business Insights and Recommendations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate business insights\\n\",\n",
    "    \"print(\\\"=== BUSINESS INSIGHTS ===\\\")\\n\",\n",
    "    \"print(f\\\"\\\\n1. Dataset Overview:\\\")\\n\",\n",
    "    \"print(f\\\"   - Total customers: {len(df):,}\\\")\\n\",\n",
    "    \"print(f\\\"   - Total features: {len(df.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"   - Numeric features: {len(numeric_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"   - Categorical features: {len(categorical_cols)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if churn_columns:\\n\",\n",
    "    \"    churn_rate = df[churn_col].value_counts(normalize=True)\\n\",\n",
    "    \"    print(f\\\"\\\\n2. Churn Analysis:\\\")\\n\",\n",
    "    \"    print(f\\\"   - Overall churn rate: {churn_rate.get(1, 0)*100:.1f}%\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Usage patterns\\n\",\n",
    "    \"usage_cols = [col for col in df.columns if 'usage' in col.lower()]\\n\",\n",
    "    \"if usage_cols:\\n\",\n",
    "    \"    print(f\\\"\\\\n3. Usage Patterns:\\\")\\n\",\n",
    "    \"    for col in usage_cols[:3]:\\n\",\n",
    "    \"        print(f\\\"   - Average {col}: {df[col].mean():.2f}\\\")\\n\",\n",
    "    \"        print(f\\\"   - {col} std deviation: {df[col].std():.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Revenue insights\\n\",\n",
    "    \"revenue_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['charge', 'fee', 'revenue', 'price'])]\\n\",\n",
    "    \"if revenue_cols:\\n\",\n",
    "    \"    print(f\\\"\\\\n4. Revenue Insights:\\\")\\n\",\n",
    "    \"    for col in revenue_cols[:3]:\\n\",\n",
    "    \"        print(f\\\"   - Average {col}: ${df[col].mean():.2f}\\\")\\n\",\n",
    "    \"        print(f\\\"   - Total {col}: ${df[col].sum():,.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n=== RECOMMENDATIONS ===\\\")\\n\",\n",
    "    \"print(f\\\"1. Focus on high-value customer segments\\\")\\n\",\n",
    "    \"print(f\\\"2. Implement predictive churn models\\\")\\n\",\n",
    "    \"print(f\\\"3. Optimize pricing strategies based on usage patterns\\\")\\n\",\n",
    "    \"print(f\\\"4. Develop targeted retention campaigns\\\")\\n\",\n",
    "    \"print(f\\\"5. Monitor key performance indicators regularly\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This exploratory data analysis provides comprehensive insights into the subscription dataset. Key findings include:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Data Quality**: Assessment of missing values, duplicates, and data types\\n\",\n",
    "    \"2. **Feature Relationships**: Correlation analysis and feature importance\\n\",\n",
    "    \"3. **Business Insights**: Customer behavior patterns and revenue analysis\\n\",\n",
    "    \"4. **Actionable Recommendations**: Strategic suggestions for business improvement\\n\",\n",
    "    \"\\n\",\n",
    "    \"The next steps would be to:\\n\",\n",
    "    \"- Train machine learning models for churn prediction\\n\",\n",
    "    \"- Develop customer segmentation strategies\\n\",\n",
    "    \"- Create recommendation systems for plan optimization\\n\",\n",
    "    \"- Build monitoring dashboards for ongoing analysis\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
